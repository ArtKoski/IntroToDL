{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- hyperparameters ---\n",
    "N_EPOCHS = 5\n",
    "LR = 0.001\n",
    "\n",
    "#--- fixed constants ---\n",
    "NUM_CLASSES = 14\n",
    "DATA_DIR = 'dataset/%s'\n",
    "NUM_CHANNELS = 3\n",
    "WIDTH, HEIGHT = 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                                        #transforms.RandomHorizontalFlip(),\n",
    "                                        #transforms.Grayscale(),\n",
    "                                        transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([\n",
    "                                        #transforms.Grayscale(),\n",
    "                                        transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(os.path.join(self.root_dir, \"images\")))\n",
    "        self.labels = {}\n",
    "        for label in ['baby', 'bird', 'car', 'clouds', 'dog', 'female', 'flower', 'male', 'night', 'people', 'portrait', 'river', 'sea', 'tree']:\n",
    "            with open(os.path.join(self.root_dir, \"annotations\", f\"{label}.txt\"), \"r\") as f:\n",
    "                f.seek(0)\n",
    "                self.labels[label] = sorted(set(f.read().splitlines()))\n",
    "                # self.labels[label] = set(f.read().splitlines()) # this is original\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.root_dir, \"images\", self.image_paths[index])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = []\n",
    "        for key, value in self.labels.items():\n",
    "            filename = os.path.basename(image_path)[2:-4]\n",
    "            # print(filename)\n",
    "            label.append(1 if filename in value else 0)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return image, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set here the path where the images and annotations are\n",
    "path = \"/Users/ocdaniel/ds/year1/idl/project/dl2021-image-corpus-proj\"\n",
    "\n",
    "# load the data\n",
    "dataset = CustomDataset(path, transform=train_transform)\n",
    "\n",
    "# Define the sizes of the splits\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset randomly into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(NUM_CHANNELS, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Epoch: 01\n",
      "\tTrain Loss: 0.898 | Train Acc: 83.74%\n",
      "\t Val. Loss: 0.840 |  Val. Acc: 87.91%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.774 | Train Acc: 92.59%\n",
      "\t Val. Loss: 0.724 |  Val. Acc: 92.61%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.711 | Train Acc: 92.83%\n",
      "\t Val. Loss: 0.703 |  Val. Acc: 92.61%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.700 | Train Acc: 92.83%\n",
      "\t Val. Loss: 0.698 |  Val. Acc: 92.61%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.697 | Train Acc: 92.83%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 92.61%\n"
     ]
    }
   ],
   "source": [
    "model = MultiLabelClassifier()\n",
    "\n",
    "# set up device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    if torch.backends.mps.is_built():\n",
    "        device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = MultiLabelClassifier().to(device)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "threshold = 0.5\n",
    "\n",
    "# parameters for early stop\n",
    "threshold = 1       # number of epochs to wait if test loss doesnt improve\n",
    "min_loss = np.inf\n",
    "counter = 0\n",
    "\n",
    "# Train your model\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0.0\n",
    "    train_total = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        predictions = (outputs > 0.5).int()\n",
    "        correct = torch.eq(predictions, labels).sum().item()\n",
    "\n",
    "        train_correct += correct\n",
    "\n",
    "        # En oo iha varma miten tätä pitäs tulkita, atm laskee siis jokasen oikeen arvauksen ja yhen kuvan sisällä on käytännössä 14 arvausta\n",
    "        train_total += labels.size(0)*NUM_CLASSES\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print('predictions',predictions)\n",
    "        # print('labels',labels)\n",
    "    \n",
    "    # calculate average loss and accuracy for epoch\n",
    "    epoch_loss = train_loss / len(train_loader)\n",
    "    epoch_accuracy = train_correct / train_total\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {epoch_loss:.3f} | Train Acc: {epoch_accuracy*100:.2f}%')\n",
    "\n",
    "    # evaluate model on validation set\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # calculate accuracy\n",
    "            predictions = (outputs > 0.5).int()\n",
    "            correct = torch.eq(predictions, labels).sum().item()\n",
    "            val_correct += correct\n",
    "\n",
    "            val_total += labels.size(0)*NUM_CLASSES\n",
    "            val_loss += loss\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    # early stopping\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= threshold:\n",
    "            print(f'Stopping early after epoch {epoch}, best loss reached.')\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.697 |  Test Acc: 92.55%\n"
     ]
    }
   ],
   "source": [
    "#--- test ---\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # calculate accuracy\n",
    "        predictions = (outputs > 0.5).int()\n",
    "        \n",
    "        correct = torch.eq(predictions, labels).sum().item()\n",
    "        test_correct += correct\n",
    "\n",
    "        test_total += labels.size(0)*NUM_CLASSES\n",
    "        test_loss += loss\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ce84d8e4502ddaac3896d19b3e19296246c03597ea522fc771d0c9d54b494e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
